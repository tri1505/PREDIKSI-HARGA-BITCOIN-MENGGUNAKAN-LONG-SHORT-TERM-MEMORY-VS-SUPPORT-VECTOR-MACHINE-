# -*- coding: utf-8 -*-
"""LSTM pt2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hgbm69598LkSs2FMWH6efkCgZpDDPOxt
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import LSTM, Dense
import matplotlib.pyplot as plt

data = pd.read_csv('dataset.csv')
print(data)

data.drop(['Date'], axis=1, inplace=True)

"""o"""

input_features = ['Price']
output_features = ['Price']

dataset = data.values
dataset = dataset.astype('float32')

scaler = MinMaxScaler(feature_range=(0, 1))
dataset = scaler.fit_transform(dataset)

print(dataset)

train_size = int(len(dataset) * 0.7)
test_size = len(dataset) - train_size
train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]

def scale(train, test):

	scaler = MinMaxScaler(feature_range=(0, 1))
	scaler = scaler.fit(train)

	train = train.reshape(train.shape[0], train.shape[1])
	train_scaled = scaler.transform(train)

	test = test.reshape(test.shape[0], test.shape[1])
	test_scaled = scaler.transform(test)
	return scaler, train_scaled, test_scaled

def create_dataset(dataset, look_back=1):
    dataX, dataY = [], []
    for i in range(len(dataset) - look_back - 1):
        a = dataset[i:(i + look_back), 0]
        dataX.append(a)
        dataY.append(dataset[i + look_back, 0])
    return np.array(dataX), np.array(dataY)

def winndowed_dataset(series,batch_size,n_past=24,n_future=24,shift=1):
    df=pd.DataFrame(series)
    ds=dataset.from_tensor_slices(df)

look_back = 15
trainX, trainY = create_dataset(train, look_back)
testX, testY = create_dataset(test, look_back)

model = Sequential()
model.add(LSTM(100, input_shape=(look_back, 1)))
model.add(Dense(1))

model.compile(loss='mean_squared_error', optimizer='adam')

trainX = np.reshape(trainX, (trainX.shape[0], look_back, 1))
testX = np.reshape(testX, (testX.shape[0], look_back, 1))

hist=model.fit(trainX, trainY, epochs=100, batch_size=32, verbose=2)

trainPredict = model.predict(trainX)
testPredict = model.predict(testX)

from sklearn.metrics import r2_score
train_r2 = r2_score(trainY, trainPredict)*100
test_r2 = r2_score(testY, testPredict)*100
print("Train R-squared:", train_r2,"%")
print("Test R-squared:", test_r2,"%")

from sklearn.metrics import mean_squared_error
mse = mean_squared_error(testY, testPredict)
print("MSE:", mse)

model_history = hist.history
loss = model_history['loss']

plt.figure()
plt.plot(loss, label='MSE')
plt.xlabel('Epoch')
plt.ylabel('MSE')
plt.title('Mse')
plt.show()

plt.plot(trainPredict, label='Predict')
plt.plot(trainY, label='Actual')
plt.xlabel('Jumlah Data')
plt.ylabel('Data')
plt.title('Data Training')
plt.legend()
plt.show()

plt.plot(testPredict, label='Predict')
plt.plot(testY, label='Actual')
plt.xlabel('Jumlah Data')
plt.ylabel('Data')
plt.title('Data Testing')
plt.legend()
plt.show()
plt.show()

all_predictions = testPredict
all_actual = testY

df = pd.DataFrame({
    'Predictions': all_predictions.flatten(),
    'Actual': all_actual.flatten()
})

df.to_csv('predictions.csv', index=False)

print(df)

plt.plot(all_predictions, label='Predict')
plt.plot(all_actual, label='Actual')
plt.xlabel('Jumlah Data')
plt.ylabel('Data')
plt.title('Prediksi Harga Bitcoin')
plt.legend()
plt.show()
plt.show()

d_min_actual = min(testY)
d_max_actual = max(testY)
print(d_min_actual)
print(d_max_actual)

denorm_actual = (data[' Price'][:95] * (d_max_actual - d_min_actual) + d_min_actual)

d_min_predict = min(testPredict)
d_max_predict = max(testPredict)
print(d_min_predict)
print(d_max_predict)

denorm_predict = (data[' Price'][:95] * (d_max_predict - d_min_predict) + d_min_predict)

hasil = pd.DataFrame({
    'Actual': denorm_actual,
    'Predict': denorm_predict
})
print(hasil)
hasil.to_excel('hasil.xlsx', index=False)

import numpy as np
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score # Import the necessary functions
import matplotlib.pyplot as plt
import seaborn as sns

y_test_norm = (testY - testY.min()) / (testY.max() - testY.min())
y_pred_norm = (testPredict - testPredict.min()) / (testPredict.max() - testPredict.min())

threshold = 0.7

y_test_classes = np.where(y_test_norm > threshold, 1, 0)
y_pred_classes = np.where(y_pred_norm > threshold, 1, 0)

cm = confusion_matrix(y_test_classes, y_pred_classes)

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted Classes")
plt.ylabel("Actual Classes")
plt.title("Confusion Matrix")
plt.show()

Accuracy = accuracy_score(y_test_classes, y_pred_classes)*100
Precision = precision_score(y_test_classes, y_pred_classes)
Recall = recall_score(y_test_classes, y_pred_classes)
f1_score = f1_score(y_test_classes, y_pred_classes)

print("Accuracy:", Accuracy, "%")
print("Precision:", Precision)
print("Recall:", Recall)
print("f1_score:", f1_score)

from sklearn.metrics import classification_report
print(classification_report(y_test_classes, y_pred_classes))