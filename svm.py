# -*- coding: utf-8 -*-
"""SVM

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dN0A-m13a_YGZoQhhsPX-e-8Sji5PaXk
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install scikit-learn
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
# %matplotlib inline

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix

from matplotlib.colors import ListedColormap

import seaborn as sns

df = pd.read_csv("dataset.csv")
display(df.head())

x = df.iloc[:, [2, 3]].values
y = df.iloc[:, 4].values

print(x[:5])
print(y[:5])

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)

std_x = StandardScaler()
x_train = std_x.fit_transform(x_train)
x_test = std_x.transform(x_test)

print("x_train:", x_train[:5], "...")
print("")
print("x_test:", x_test[:5], "...")

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression

imputer = SimpleImputer(strategy='mean')

x_train = imputer.fit_transform(x_train)
x_test = imputer.transform(x_test)

y_train = imputer.fit_transform(y_train.reshape(-1, 1)).ravel()
model = LinearRegression()
model.fit(x_train, y_train)

print(model.intercept_)
print(model.coef_)

y_pred = model.predict(x_test)
print(y_pred[:5])

from sklearn.metrics import r2_score
train_r2 = r2_score(y_test, y_pred)*100
test_r2 = r2_score(y_train, model.predict(x_train))*100
print("Test R-squared:", train_r2,"%")
print("Train R-squared:", test_r2,"%")

from sklearn.metrics import mean_squared_error

mse = mean_squared_error(y_test, y_pred)/1000000

print("MSE:", mse)

residuals = y_test - y_pred
plt.scatter(y_pred, residuals)
plt.xlabel("Predicted Values")
plt.ylabel("Residuals")
plt.title("Residual Plot")
plt.show()

residuals = y_test - y_pred
plt.scatter(y_test, residuals)
plt.xlabel("Actual Values")
plt.ylabel("Residuals")
plt.title("Residual Plot")
plt.show()

import numpy as np
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

y_test_norm = (y_test - y_test.min()) / (y_test.max() - y_test.min())
y_pred_norm = (y_pred - y_pred.min()) / (y_pred.max() - y_pred.min())

threshold = 0.2

y_test_classes = np.where(y_test_norm > threshold, 1, 0)
y_pred_classes = np.where(y_pred_norm > threshold, 1, 0)
cm = confusion_matrix(y_test_classes, y_pred_classes)

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted Classes")
plt.ylabel("Actual Classes")
plt.title("Confusion Matrix")
plt.show()

from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score

Accuracy = accuracy_score(y_test_classes, y_pred_classes)*100
precision = precision_score(y_test_classes, y_pred_classes, average='macro')
recall = recall_score(y_test_classes, y_pred_classes, average='macro')
f1 = f1_score(y_test_classes, y_pred_classes, average='macro')

print("Accuracy:", Accuracy, "%")
print("Precision (macro):", precision)
print("Recall (macro):", recall)
print("F1-score (macro):", f1)

from sklearn.metrics import classification_report
print(classification_report(y_test_classes, y_pred_classes))

hasil = pd.DataFrame({
    'Actual': y_test_classes,
    'Predict': y_pred_classes
})
print(hasil)
hasil.to_excel('predictions normalize.xlsx',  index=False)

output = pd.DataFrame({
    'Actual': y_test,
    'Predict': y_pred
})
print(output)
output.to_excel('predictions denormalize.xlsx',  index=False)